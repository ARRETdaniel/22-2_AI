% ----------------------------------------------------------


\chapter[Fundamentação Teórica]{Fundamentação Teórica}\label{Fundamentacao}
\begin{enumerate}
   \item  Como contribuição teórica inicial para o nosso projeto, temos o material do canal no Youtube 'Python Engineer' a playlist de vídeo aulas,  'Chat Bot With PyTorch - NLP Beginner Tutorial' \footnote{\url{https://www.youtube.com/playlist?list=PLqnslRFeH2UrFW4AUgn-eY37qOAWQpJyg}}. A partir desse conteúdo poderemos dar início aos nossos desenvolvimentos e pesquisas. No tutorial, é desenvolvido um chatbot simples usando PyTorch e Deep Learning. Também fornecendo uma introdução a algumas técnicas básicas de Processamento de Linguagem Natural (PLN).

   \item Seguiremos, também, os conteúdos já aprendidos nas aulas de  'Inteligência Artifical 2022/2 - UENF' para nos auxiliar na formulação teórica do nosso projeto.

   \item  Salientamos que com o decorrer do projeto nossas referências de materiais, para esse projeto, tenderá a aumentar devido a novas descobertas.
\end{enumerate}







\chapter[Metodologia]{Metodologia}

Baseado no “Project-based learning” \cite{krajcik2006project}. Seguiremos os estudos através de um projeto que aborda problemas do mundo real, cujo muitos não tem resposta única. Ao longo desse projeto será possível fazer novas perguntas e encontrar suas possíveis respostas por meio de uma investigação sustentada.

\justifying
\vspace {1mm}

Este Plano de Pesquisa também utilizará as seguintes metodologias:
\begin{itemize}
   \item \textit{Pesquisa Exploratória; visando promover o enriquecimento do conhecimento sobre os diferentes assuntos relacionados a IA, ML, e Chatbots:
         }
         \begin{itemize}
            \item \textit{Levantamento Bibliográfico;}
            \item \textit{Levantamento documental;}
            \item \textit{Minicursos e Vídeo aulas;}
            \item \textit{Obtenção de experiências.}
         \end{itemize}
\end{itemize}

\chapter[Construindo um Chatbot com Pytorch]{Construindo um Chatbot com Pytorch}

Já pensou em como Alexa, Siri ou assistente de voz do Google funcionavam? Neste capítulo daremos início à construção de um chatbot para interação com usuários de uma loja virtual.

Antes de continuar, abaixo encontra-se a lista de requisitos para o nosso projeto:
\justifying
\begin{itemize}
   \item \textit{Python 3}
         \begin{itemize}
            \item \textit{Define: Python} é uma linguagem de programação interpretada, orientada a objetos e de alto nível com semântica dinâmica. Suas estruturas de dados embutidas de alto nível, combinadas com tipagem dinâmica e vinculação dinâmica, o tornam muito atraente para o Desenvolvimento Rápido de Aplicativos e para uso como uma linguagem de script ou cola para conectar componentes existentes \footnote{\url{https://www.python.org/doc/essays/blurb/}}.
         \end{itemize}

   \item \textit{Dictionaries e Lists}
         \begin{itemize}
            \item \textit{Define: Listas} são tipos de dados mutáveis em Python. Lists é um tipo de dados de índice baseado em 0, o que significa que o índice do primeiro elemento começa em 0. As listas são usadas para armazenar vários itens em uma única variável. As listas são um dos 4 tipos de dados do Python, ou seja, Listas, Dicionário, Tupla e Conjunto \footnote{\url{https://www.analyticsvidhya.com/blog/2021/06/working-with-lists-dictionaries-in-python/}}.
            \item \textit{Define: Dicionários} Dicionários são a implementação do Python de uma estrutura de dados que é mais conhecida como uma matriz associativa. Um dicionário consiste em uma coleção de pares chave-valor. Cada par de chave-valor mapeia a chave para seu valor associado\footnote{\url{https://realpython.com/python-dicts}}.
         \end{itemize}

   \item \textit{NumPy}
         \begin{itemize}
            \item \textit{Define: NumPy} é o pacote fundamental para computação científica em Python. É uma biblioteca Python que fornece um objeto array multidimensional, vários objetos derivados (como arrays e matrizes mascarados) e uma variedade de rotinas para operações rápidas em arrays, incluindo matemática, lógica, manipulação de formas, classificação, seleção, E/S , Fourier discreto transforma álgebra linear básica, operações estatísticas básicas, simulação aleatória e muito mais\footnote{\url{https://numpy.org/doc/stable/user/whatisnumpy.html}}.
         \end{itemize}

   \item \textit{Pandas}
         \begin{itemize}
            \item \textit{Define: Pandas} é um pacote Python de código aberto que é mais amplamente usado para ciência de dados/análise de dados e tarefas de aprendizado de máquina. Ele é construído em cima de outro pacote chamado Numpy, que fornece suporte para arrays multidimensionais\footnote{\url{https://www.activestate.com/resources/quick-reads/what-is-pandas-in-python-everything-you-need-to-know/}}.
         \end{itemize}

   \item \textit{Pytorch}
         \begin{itemize}
            \item \textit{Define: PyTorch} é uma biblioteca de aprendizado de máquina para Python usada principalmente para processamento de linguagem natural. O software de código aberto foi desenvolvido pelas equipes de inteligência artificial do Facebook Inc. em 2016. O PyTorch oferece dois recursos significativos, incluindo computação de tensor, bem como redes neurais profundas funcionais\footnote{\url{https://deepai.org/machine-learning-glossary-and-terms/pytorch}}.
         \end{itemize}

   \item \textit{Natural Language Processing (Bag of Words)}
         \begin{itemize}
            \item \textit{Define: NLP ou PLN }O processamento de linguagem natural usa aprendizado de máquina para revelar a estrutura e o significado do texto. Com aplicativos de processamento de linguagem natural, as organizações podem analisar texto e extrair informações sobre pessoas, lugares e eventos para entender melhor o sentimento da mídia social e as conversas com os clientes \footnote{\url{https://cloud.google.com/learn/what-is-natural-language-processing}}.
         \end{itemize}


\end{itemize}

\section[Importando Bibliotecas Relevantes]{Importando Bibliotecas Relevantes}
\begin{lstlisting}[language=Python, caption=Python Bibliotecas]

   import numpy as np
   import random
   import json
   import nltk
   import torch
   import torch.nn as nn
   from torch.utils.data import Dataset, DataLoader
\end{lstlisting}


\section[Criando funções personalizadas]{Criando funções personalizadas}
Criaremos funções personalizadas para que seja fácil implementá-las posteriormente.
\justifying
\begin{lstlisting}[language=Python, caption=Python Funções personalizadas]
def tokenize(sentence):
    return nltk.word_tokenize(sentence)

def stem(word):
    return stemmer.stem(word.lower())

\end{lstlisting}
Nltk ou kit de ferramentas de linguagem natural é uma biblioteca realmente útil que contém classes importantes que serão úteis em qualquer uma de suas tarefas de PNL.
\justifying
\section[Stemming]{Stemming}


Se tivermos as seguintes palavras como Andei, Ande, Andarei, Andamento, Andando, Andante, podem parecer palavras diferentes, mas geralmente têm o mesmo significado e também a mesma forma base; "and".
O processo de stemização (do inglês, stemming) consiste em reduzir uma palavra ao seu radical. A palavra “meninas” se reduziria a “menin”, assim como “meninos” e “menininhos”. As palavras “gato”, “gata”, “gatos” e “gatas” reduziriam-se para “gat” \footnote{\url{https://www.computersciencemaster.com.br/como-reduzir-uma-palavra-ao-seu-radical-em-python-stemming/}}.
Então, para que nosso modelo entenda todas as formas diferentes das mesmas palavras, precisamos treinar nosso modelo com essa forma. Isso é chamado de Stemming. Existem diferentes métodos que podemos usar para derivação. Aqui usaremos o modelo Porter Stemmer da nossa biblioteca NLTK.
\justifying
\begin{lstlisting}[language=Python, caption=Python Stemming]
from nltk.stem.porter import PorterStemmer
stemmer = PorterStemmer()
\end{lstlisting}

\section[Bag of Words]{Bag of Words}
Vamos dividir cada palavra em frases e adicioná-la a um array. Nós estaremos usando um saco de palavras. Que inicialmente será uma lista de zeros com um tamanho igual ao comprimento do array all-words. Se tivermos um array de ` frases = ["ola", "como", "voce", "esta"]` e um array de total ` words = ["oi", "olá", "eu", "você, "tchau", "obrigado", "legal"]` então seu conjunto de palavras será `bog = [ 0 , 1 , 0 , 1 , 0 , 0 , 0]`. Faremos um loop sobre cada palavra no array all-words e o array bog correspondente a cada palavra. Se uma palavra da frase for encontrada no array all words, 1 será substituído naquele índice/posição no array bag.
\justifying


\begin{figure}[H]
   \begin{center}
      \includegraphics[width=15cm]{img/bagofwords.png}
      \caption{Bag of Words} \label{BagofWords}
      \medskip
      \small
      Usa Bag of Words para separar uma frase em várias palavras. Imagem retirada da Fundamentação Teórica \ref{Fundamentacao}.
   \end{center}
\end{figure}


\begin{lstlisting}[language=Python, caption=Python Bag of Words]
def bag_of_words(tokenized_sentence, words):
    """
    return bag of words array:
    1 para cada palavra conhecida que existe na frase,
    0 caso contrario.


    Exem,plo:


    sentence = ["ola", "como", "esta", "voce"]
    words = ["oi", "ola", "eu", "voce", "tchau",
     "obrigado", "legal"]
    bag   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]
    """
    # stem cada palavra
    sentence_words = [stem(word) for word in tokenized_sentence]
    # initialize bag com 0 para cada palavra
    bag = np.zeros(len(words), dtype=np.float32)
    for idx, w in enumerate(words):
        if w in sentence_words:
            bag[idx] = 1

    return bag

\end{lstlisting}

Durante o processo, também usaremos \textbf{nltkwordtokenize()} que converterá uma única string de sentença em uma lista de palavras. Por exemplo, se você passar \textbf{"Ola, como voce esta?"}, ele retornará \textbf{"ola", "como", "voce", "esta"}.
\textbf{Observação:} Passaremos palavras em minúsculas para o \textbf{Stemmer} para que palavras como Bom e bom (em maiúsculas) não sejam rotuladas como palavras diferentes.

\section[Carregando os dados e Data Cleaning]{Carregando os dados e Data Cleaning}
Usaremos um conjunto de dados chamado  \textbf{intents.json} que tem a estrutura mostrada no campo abaixo. Estaremos limpando esses dados de acordo com as nossas necessidades usando as funções que criamos anteriormente.

\begin{lstlisting}[language=python, caption=Data intents.json]
{
  "intents": [
    {
      "tag": "saudacao",
      "patterns": [
        "Oi",
        "Ei",
        "Como voce esta",
        "Tem alguem ai?",
        "Ola",
        "Bom dia"
      ],
      "responses": [
        "Ei :-)",
        "Ola, obrigado pela visita",
        "Ola, o que posso fazer por voce?",
        "Ola, como posso ajudar?"
      ]
   }
  ]
}


\end{lstlisting}
Agora vamos simplesmente carregar o arquivo json usando a função \textbf{jsonload}.

\begin{lstlisting}[language=Python, caption=Python Carregando dados]
with open('intents.json', 'r') as f:
    intents = json.load(f)
\end{lstlisting}

Para obter as informações corretas, iremos descompactá-las com o seguinte código:

\begin{lstlisting}[language=Python, caption=Python Loop nos dados]
all_words = []
tags = []
xy = []
# loop atraves de cada frase no nosso intents patterns
for intent in intents['intents']:
    tag = intent['tag']
    # adicionar a tag list
    tags.append(tag)
    for pattern in intent['patterns']:
        # tokenize cada palavra na frase
        w = tokenize(pattern)
        # adicionar a nossa lista de palavras
        all_words.extend(w)
        # adicionar ao par xy
        xy.append((w, tag))

\end{lstlisting}
Isso separará todas as tags e palavras em suas listas.

\section[Limpeza e preparação dos dados]{Limpeza e preparação dos dados}


Estaremos usando nossas funções personalizadas e limpando os dados implementando as funções que criamos em nossas células anteriores.

\begin{lstlisting}[language=Python, caption=Data Cleaning]

# stem e lower cada palavra
ignore_words = ['?', '.', '!']
all_words = [stem(w) for w in all_words if w not in ignore_words]
# remover duplicados e sort
all_words = sorted(set(all_words))
tags = sorted(set(tags))

print(len(xy), "patterns") # padroes
print(len(tags), "tags:", tags) # tags
print(len(all_words), "unique stemmed words:", all_words) # palavras derivadas unicas

\end{lstlisting}

Criando dados de treinamento: transformaremos os dados em um formato que nosso modelo PyTorch possa entender facilmente

\begin{lstlisting}[language=Python, caption=Training Data]

# criar dados de treinamento
X_train = []
y_train = []
for (pattern_sentence, tag) in xy:
    # X: bag de palavras para cada pattern_sentence
    bag = bag_of_words(pattern_sentence, all_words)
    X_train.append(bag)
    # y: PyTorch CrossEntropyLoss precisa apenas class labels, nao one-hot
    label = tags.index(tag)
    y_train.append(label)

X_train = np.array(X_train)
y_train = np.array(y_train)

\end{lstlisting}

\section[Modelo PyTorch]{Modelo PyTorch}

Aqui estaremos fazendo uma classe para implementar nossa rede neural personalizada. Será uma Rede neural feed-forward que terá 3 Camadas Lineares e usaremos a função de ativação “ReLU”. Nota: Usamos a função super() para herdar as propriedades de sua classe pai. Este é um conceito de Programação Orientada a Objetos (OOP).

\begin{itemize}
   \item \textit{Define: ReLU} é uma função de ativação não linear que é usada em redes neurais multicamadas ou redes neurais profundas. Esta função pode ser representada como:

         \begin{figure}[H]
            \begin{center}
               \includegraphics[width=10cm]{img/relu.jpg}
               \caption{ReLu} \label{ReLu}
               \medskip
               \small
               onde x = um valor de entrada.
            \end{center}
         \end{figure}

         De acordo com a equação 1, a saída de ReLu é o valor máximo entre zero e o valor de entrada. A saída é igual a zero quando o valor de entrada é negativo e o valor de entrada quando a entrada é positiva. Assim, podemos reescrever a equação 1 da seguinte forma:

         \begin{figure}[H]
            \begin{center}
               \includegraphics[width=10cm]{img/relu2.jpg}
               \caption{ReLu} \label{ReLu2}
               \medskip
               \small
               onde x = um valor de entrada.
            \end{center}
         \end{figure}


         Exemplos de ReLu: Dadas diferentes entradas, a função gera diferentes saídas. Por exemplo, quando x é igual a -5, a saída de f(-5) é 0. Por outro lado, a saída de f(0) é 0 porque a entrada é maior ou igual a 0. Além disso, o resultado de f (5) é 5 porque a entrada é maior que zero \footnote{\url{https://deepai.org/machine-learning-glossary-and-terms/relu/}}.
\end{itemize}

\subsection[Feed Forward Neural Network]{Feed Forward Neural Network}

\textit{Define: Feed Forward Neural Network} Uma Rede Neural Feed Forward é uma rede neural artificial na qual as conexões entre os nós não formam um ciclo. O oposto de uma rede neural feed-forward é uma rede neural recorrente, na qual certos caminhos são ciclados. O modelo feed-forward é a forma mais simples de uma rede neural, pois a informação é processada apenas em uma direção. Embora os dados possam passar por vários nós ocultos, eles sempre se movem em uma direção e nunca para trás \footnote{\url{https://deepai.org/machine-learning-glossary-and-terms/feed-forward-neural-network}}.


\begin{figure}[H]
   \begin{center}
      \includegraphics[width=10cm]{img/ffnn.png}
      \caption{Feed Forward Neural Network} \label{ffnn}
      \medskip
      \small
      Exemplo de uma rede neural feed-forward.
   \end{center}
\end{figure}

Desse modo, uma representação válida para o nosso projeto seria a FFNN abaixo:
\begin{figure}[H]
   \begin{center}
      \includegraphics[width=10cm]{img/ffnn2.png}
      \caption{Feed Forward Neural Network} \label{ffnn2}
      \medskip
      \small
      Exemplo de uma rede neural feed-forward para o nosso projeto. Imagem retirada da Fundamentação Teórica \ref{Fundamentacao}.
   \end{center}
\end{figure}

\subsection[Função de ativação]{Função de ativação}

\textit{Define: Função de ativação} Uma função de ativação é uma função usada em redes neurais artificiais que produz um valor pequeno para entradas pequenas e um valor maior se suas entradas excederem um limite. Se as entradas forem grandes o suficiente, a função de ativação "dispara", caso contrário não faz nada. Em outras palavras, uma função de ativação é como um portão que verifica se um valor de entrada é maior que um número crítico.

As funções de ativação são úteis porque adicionam não linearidades às redes neurais, permitindo que as redes neurais aprendam operações poderosas. Se as funções de ativação fossem removidas de uma rede neural feedforward, toda a rede poderia ser refatorada para uma simples operação linear ou transformação de matriz em sua entrada e não seria mais capaz de realizar tarefas complexas, como reconhecimento de imagem \footnote{\url{https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6}}.

\subsubsection[Função ReLU]{Função ReLU}
Atualmente, existem várias funções de ativação amplamente usadas no aprendizado profundo. Uma das mais simples é a ReLU (Rectified Linear Unit) Activation Function, ou função ReLU, que é uma função linear por partes que produz zero se sua entrada for negativa, e diretamente a saída caso contrário.
Como mencionado, O ReLU é a função de ativação mais usada no mundo atualmente. Já que é usado em quase todas as redes neurais convolucionais ou deep learning.

\begin{figure}[H]
   \begin{center}
      \includegraphics[width=10cm]{img/relu.png}
      \caption{ReLU v/s Logistic Sigmoid} \label{relu}
   \end{center}
\end{figure}
Como você pode identificar, o ReLU está meio retificado (de baixo). f(z) é zero quando z é menor que zero e f(z) é igual a z quando z é maior ou igual a zero.

Range: [ 0 ao infinito)

A função e sua derivada são monotônicas.

Mas o problema é que todos os valores negativos se tornam zero imediatamente, o que diminui a capacidade do modelo de ajustar ou treinar a partir dos dados corretamente. Isso significa que qualquer entrada negativa dada à função de ativação ReLU transforma o valor em zero imediatamente no gráfico, o que, por sua vez, afeta o gráfico resultante por não mapear os valores negativos adequadamente\footnote{\url{https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6}}.

\subsubsection[Derivada da Função ReLU]{Derivada da Função ReLU}

Em redes neurais, uma função de ativação agora comumente usada é a unidade linear retificada, ou como comumente abreviada, ReLU. O ReLU é definido como,

\begin{figure}[H]
   \begin{center}
      \includegraphics[width=10cm]{img/relu2.png}
      \caption{A representação matemática da função ReLU} \label{relu2}
       \end{center}
\end{figure}

O que essa função faz? Basicamente, ele define qualquer coisa menor ou igual a 0 (números negativos) como 0. E mantém todos os mesmos valores para quaisquer valores > 0 \footnote{\url{https://kawahara.ca/what-is-the-derivative-of-relu/}}.

Também é instrutivo calcular o gradiente da função ReLU, que é matematicamente indefinida em x = 0, mas que ainda é extremamente útil em redes neurais.

A derivada da função ReLU. Na prática, a derivada em x = 0 pode ser definida como 0 ou 1.
A derivada zero para x negativo pode dar origem a problemas ao treinar uma rede neural,
pois um neurônio pode ficar 'preso' na região zero e a retropropagação (backpropagation) nunca mudará seus pesos.
Em outras palavras, digamos que tenhamos entrada menor que 0, então a saída é zero e a rede neural não pode continuar o algoritmo de retropropagação. Esse problema é comumente conhecido como Dying ReLU. Para nos livrarmos desse problema, usamos uma versão improvisada do ReLU, chamada Leaky ReLU (Cujo nao cobrimos nesse projeto) \footnote{\url{https://vidyasheela.com/post/what-is-the-derivative-of-the-relu-activation-function-including-python-function}}.

\begin{figure}[H]
   \begin{center}
      \includegraphics[width=10cm]{img/relu3.png}
      \caption{A derivada da função ReLU} \label{relu3}
       \end{center}
\end{figure}


\subsection[Criando nosso modelo]{Criando nosso modelo}

\begin{lstlisting}[language=Python, caption=Modelo]

class NeuralNet(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(NeuralNet, self).__init__()
        self.l1 = nn.Linear(input_size, hidden_size)
        self.l2 = nn.Linear(hidden_size, hidden_size)
        self.l3 = nn.Linear(hidden_size, num_classes)
        self.relu = nn.ReLU()

    def forward(self, x):
        out = self.l1(x)
        out = self.relu(out)
        out = self.l2(out)
        out = self.relu(out)
        out = self.l3(out)
        # sem ativacao e sem softmax no final
        return out

\end{lstlisting}

Aqui nós herdamos uma classe do NN.Module porque estaremos customizando o modelo e suas camadas.


\section[Atribuindo o conjunto de dados ao modelo]{Atribuindo o conjunto de dados ao modelo}

Usaremos algumas funções de Magic, escreva nossa classe.

\textit{Define: funções de Magic} ou Métodos mágicos são métodos especiais em python que possuem sublinhados duplos (dunder) em ambos os lados do nome do método. Métodos mágicos são predominantemente usados para sobrecarga do operador. Sobrecarga de operador significa fornecer funcionalidade adicional aos operadores, o python invoca implicitamente os métodos mágicos para fornecer funcionalidade adicional a ele. Por exemplo, a multiplicação de dois inteiros pode ser feita usando o operador de multiplicação (2*3 = 6) e o mesmo operador pode ser usado para repetir a string (“maçã-” * 3 = ‘maçã- maçã- maçã’).
Alguns exemplos de métodos mágicos são init, len, repr, add e etc \footnote{\url{https://www.analyticsvidhya.com/blog/2021/08/explore-the-magic-methods-in-python}}\footnote{\url{https://www.geeksforgeeks.org/dunder-magic-methods-python/}}.


\begin{itemize}
 \item O método init para inicialização é invocado sem qualquer chamada, quando uma instância de uma classe é criada, como construtores em algumas outras linguagens de programação, como C++, Java, PHP etc. Esses métodos são a razão pela qual podemos adicionar duas strings com ' +' operador sem qualquer typecast explícito.
 \item O método getitem é usado para obter um item do atributo das instâncias invocadas. getitem é comumente usado com contêineres como lista, tupla, etc.
 \item O método mágico len é usado para encontrar o comprimento dos atributos da instância. Quando usamos len(instance), ele retorna o comprimento do atributo de instância que geralmente é um container.
\end{itemize}

\begin{lstlisting}[language=Python, caption=Dataset]
class ChatDataset(Dataset):

    def __init__(self):
        self.n_samples = len(X_train)
        self.x_data = X_train
        self.y_data = y_train

    # suporte a indexacao de modo que o conjunto de dados[i] possa ser usado para obter a i-esima amostra

    def __getitem__(self, index):
        return self.x_data[index], self.y_data[index]

    # podemos chamar len(dataset) para retornar o tamanho
    def __len__(self):
        return self.n_samples

\end{lstlisting}


\section[Hiperparâmetros]{Hiperparâmetros}
Toda rede neural tem um conjunto de hiperparâmetros que precisam ser definidos antes do uso.

Antes de instanciar nossa classe ou modelo de rede neural que escrevemos anteriormente, primeiro definiremos alguns hiperparâmetros que podem ser alterados de acordo.

Os hiperparâmetros são parâmetros cujos valores controlam o processo de aprendizado e determinam os valores dos parâmetros do modelo que um algoritmo de aprendizado acaba aprendendo. O prefixo hyper sugere que são parâmetros de nível superior que controlam o processo de aprendizagem e os parâmetros do modelo que dele resultam.

Um engenheiro de aprendizado de máquina projetando um modelo, faz a escolha de definer valores de hiperparâmetros que seu algoritmo de aprendizado usará antes mesmo do início do treinamento do modelo. Sob essa luz, os hiperparâmetros são considerados externos ao modelo porque o modelo não pode alterar seus valores durante o aprendizado/treinamento\footnote{\url{https://towardsdatascience.com/parameters-and-hyperparameters-aa609601a9ac}}\footnote{\url{https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch}}\footnote{\url{https://www.javatpoint.com/hyperparameters-in-machine-learning}}.


Hiperparâmetros:


\begin{itemize}
 \item  \textit{Define: Epoch} O número de épocas é um hiperparâmetro que define o número de vezes que o algoritmo de aprendizado funcionará em todo o conjunto de dados de treinamento.

Uma época significa que cada amostra no conjunto de dados de treinamento teve a oportunidade de atualizar os parâmetros internos do modelo.

Você pode pensar em um loop for sobre o número de épocas em que cada loop prossegue no conjunto de dados de treinamento. Dentro desse loop for há outro loop for aninhado que itera sobre cada lote de amostras, onde um lote tem o número de amostras "tamanho de lote" especificado.

O número de épocas é tradicionalmente grande, geralmente centenas ou milhares, permitindo que o algoritmo de aprendizado seja executado até que o erro do modelo seja suficientemente minimizado. Você pode ver exemplos do número de épocas na literatura e em tutoriais definidos para 10, 100, 500, 1000 e maiores.

\item \textit{Define: Batch} O tamanho do Batch é um hiperparâmetro que define o número de amostras para trabalhar antes de atualizar os parâmetros do modelo interno.

Pense em um Batch como um loop for iterando sobre uma ou mais amostras e fazendo previsões. No final do Batch , as previsões são comparadas com as variáveis de saída esperadas e um erro é calculado. A partir desse erro, o algoritmo de atualização é usado para melhorar o modelo, por exemplo. mover para baixo ao longo do gradiente de erro.

\item \textit{Define: Learnin Rate} O hiperparâmetro de taxa de aprendizado controla a taxa ou velocidade na qual o modelo aprende. Especificamente, ele controla a quantidade de erro distribuído com o qual os pesos do modelo são atualizados cada vez que são atualizados, como no final de cada lote de exemplos de treinamento.

\item \textit{Define: Hidden Units} As unidades ocultas fazem parte das redes neurais, que se referem aos componentes que compõem as camadas de processadores entre as unidades de entrada e saída em uma rede neural. É importante especificar o número de hiperparâmetros de unidades ocultas para a rede neural. Deve estar entre o tamanho da camada de entrada e o tamanho da camada de saída. Mais especificamente, o número de unidades ocultas deve ser 2/3 do tamanho da camada de entrada, mais o tamanho da camada de saída.

\end{itemize}


Veja mais sobre Hiperparâmetros aqui \footnote{\url{https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch}}.




\begin{lstlisting}[language=Python, caption=Hiperparâmetros]
# Hiperparametros
num_epochs = 1000
batch_size = 8
learning_rate = 0.001
input_size = len(X_train[0])
hidden_size = 8
output_size = len(tags)
print(input_size, output_size)

\end{lstlisting}

\section[Perda e otimizador]{Perda e otimizador}

Vamos agora instanciar as funções de modelo, perda e otimizador.

     Função de Perda: Cross Entropy
     Otimizador: Adam Optimizer

\begin{lstlisting}[language=Python, caption=Perda e otimizador]
dataset = ChatDataset()
train_loader = DataLoader(dataset=dataset,
                          batch_size=batch_size,
                          shuffle=True,
                          num_workers=0)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model = NeuralNet(input_size, hidden_size, output_size).to(device)

# Perda e otimizador
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

\end{lstlisting}
